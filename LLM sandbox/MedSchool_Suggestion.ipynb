{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt\n",
    "สร้าง dynamic prompt โดยแบ่งแยกโดยคะแนนที่น้องทำได้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt_from_row(row):\n",
    "    # Skip processing if INCORRECT_SUBTOPIC_LIST is empty or null for scores of 0\n",
    "    if row['SCORE_PCT'] == 0 and (pd.isna(row['INCORRECT_SUBTOPIC_LIST']) or row['INCORRECT_SUBTOPIC_LIST'].strip() == \"\"):\n",
    "        return None\n",
    "\n",
    "    if row['SCORE_PCT'] == 0:\n",
    "        # Tailored prompt for students who scored 0 but have areas to improve, in Thai\n",
    "        return f\"\"\"\n",
    "        ### CONTEXT:\n",
    "        ให้คำแนะนำสำหรับนักเรียนที่เริ่มต้นด้วยความท้าทายอย่างมาก เนื่องจากพวกเขาได้คะแนน 0 การให้การสนับสนุนและแนวทางในหัวข้อพื้นฐานเพื่อการปรับปรุงเป็นสิ่งสำคัญ\n",
    "        \n",
    "        ### TASK:\n",
    "        - พิจารณาความท้าทายที่พบและให้คำแนะนำที่สนับสนุนและสามารถดำเนินการได้จริงเกี่ยวกับหัวข้อใน INCORRECT_SUBTOPIC_LIST นี้ [{row['INCORRECT_SUBTOPIC_LIST']}] เพื่อช่วยให้พวกเขาเริ่มต้นการเดินทางสู่ความเข้าใจและคะแนนที่สูงขึ้น\n",
    "        - Include all INCORRECT_SUBTOPIC_LIST in your advice.\n",
    "        \n",
    "        ### OUTPUT:\n",
    "        - คำแนะนำสั้นๆที่ชัดเจนและกระชับ ไม่เกิน 30 คำ\n",
    "        - ใช้ภาษาไทย\n",
    "        \"\"\"\n",
    "    elif row['SCORE_PCT'] == 1:\n",
    "        # Tailored prompt for students who scored 1, in Thai\n",
    "        return \"\"\"\n",
    "        ### CONTEXT:\n",
    "        ขอแสดงความยินดีด้วยที่คุณทำได้คะแนนเต็ม! แม้ว่าคุณจะบรรลุความสำเร็จในระดับสูงสุด แต่อย่าลืมว่าการเรียนรู้เป็นเส้นทางที่ไม่มีที่สิ้นสุดและยังมีพื้นที่สำหรับการเติบโตต่อไป\n",
    "        \n",
    "        ### TASK:\n",
    "        - แม้คุณจะได้คะแนนเต็มแล้ว เรายังต้องการให้คำแนะนำเพิ่มเติมเพื่อช่วยเสริมความรู้และทักษะของคุณ\n",
    "        - ให้คำแนะนำที่สนับสนุนและกระตุ้นใจสำหรับการปรับปรุงและการเติบโตต่อไป\n",
    "        \n",
    "        ### OUTPUT:\n",
    "        - คำแนะนำสั้นๆที่ชัดเจนและกระชับ ไม่เกิน 30 คำ\n",
    "        - ใช้ภาษาไทย\n",
    "        \"\"\"\n",
    "    elif 0.61 <= row['SCORE_PCT'] < 1:\n",
    "        # Tailored prompt for scores between 0.61 to 0.99, in Thai\n",
    "        return f\"\"\"\n",
    "        ### CONTEXT:\n",
    "        ให้คำแนะนำสำหรับนักเรียนที่ทำได้ดีแล้ว แต่ยังมีเส้นทางให้พัฒนาเพื่อบรรลุความสมบูรณ์แบบ เราต้องการช่วยให้พวกเขาเห็นคุณค่าของการปรับปรุงอย่างต่อเนื่อง\n",
    "        \n",
    "        ### TASK:\n",
    "        - พิจารณาหัวข้อใน INCORRECT_SUBTOPIC_LIST นี้ [{row['INCORRECT_SUBTOPIC_LIST']}] ที่พวกเขายังสามารถเรียนรู้เพื่อปรับปรุงได้ เพื่อช่วยให้พวกเขาก้าวหน้าและเพิ่มคะแนนให้สูงขึ้น\n",
    "        - ให้คำแนะนำที่สนับสนุนและกระตุ้นใจสำหรับการปรับปรุง\n",
    "        - Include all INCORRECT_SUBTOPIC_LIST in your advice.\n",
    "        \n",
    "        ### OUTPUT:\n",
    "        - คำแนะนำสั้นๆที่ชัดเจนและกระชับ ไม่เกิน 30 คำ\n",
    "        - ใช้ภาษาไทย\n",
    "        \"\"\"\n",
    "    else:\n",
    "        # Tailored prompt for scores below 0.61, in Thai\n",
    "        return f\"\"\"\n",
    "        ### CONTEXT:\n",
    "        ให้คำแนะนำสำหรับนักเรียนที่ต้องการการสนับสนุนเพิ่มเติม เนื่องจากพวกเขาได้คะแนนต่ำกว่า 0.61 เราต้องการให้พวกเขารู้สึกว่ายังมีโอกาสในการปรับปรุงและเราพร้อมที่จะช่วยเหลือ\n",
    "        \n",
    "        ### TASK:\n",
    "        - พิจารณาหัวข้อใน INCORRECT_SUBTOPIC_LIST นี้ [{row['INCORRECT_SUBTOPIC_LIST']}] ที่ต้องการความช่วยเหลือเพิ่มเติมในการเรียน เพื่อเพิ่มคะแนนและปรับปรุงความเข้าใจ\n",
    "        - สร้างคำแนะนำที่สร้างสรรค์และมีประโยชน์\n",
    "        - Include all INCORRECT_SUBTOPIC_LIST in your advice.\n",
    "        \n",
    "        ### OUTPUT:\n",
    "        - คำแนะนำสั้นๆที่ชัดเจนและกระชับ ไม่เกิน 30 คำ\n",
    "        - ใช้ภาษาไทย\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load ข้อมูล"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure to use the correct path to your CSV file\n",
    "df = pd.read_csv(r'C:\\Users\\nuttapong.but\\Downloads\\MedSchool_SuggestinList.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### สร้างฟังชั่นเพื่อใช้โมเดล"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "# Set your OpenAI API key here\n",
    "openai.api_key = 'replace with your api key'\n",
    "\n",
    "def query_openai_model(prompt, model=\"gpt-3.5-turbo-0125\", temperature=0):\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"\"\"\n",
    "                        - เพศหญิง\n",
    "                        - คุณครู\n",
    "                        - ใส่ใจ\n",
    "                        - แทนตัวเองว่า 'พี่'\n",
    "                        - แทนนักเรียนว่า 'น้อง'\n",
    "                    \"\"\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message['content']\n",
    "    except Exception as e:\n",
    "        return str(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loop กับขั้อมูล และ ส่งออกเป็น csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process rows as per your requirements\n",
    "for index, row in df.iterrows():\n",
    "    prompt = generate_prompt_from_row(row)\n",
    "    if prompt is None:\n",
    "        continue  # Skip processing this row\n",
    "    suggestion = query_openai_model(prompt, temperature=0)\n",
    "    df.at[index, 'Suggestions'] = suggestion\n",
    "\n",
    "# Save the updated DataFrame\n",
    "df.to_csv(r'C:\\Users\\nuttapong.but\\Downloads\\MedSchool_SuggestionList_OpenAI.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting anthropic\n",
      "  Downloading anthropic-0.21.3-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\nuttapong.but\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anthropic) (3.7.1)\n",
      "Collecting distro<2,>=1.7.0 (from anthropic)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from anthropic)\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\nuttapong.but\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anthropic) (2.4.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\nuttapong.but\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anthropic) (1.3.0)\n",
      "Collecting tokenizers>=0.13.0 (from anthropic)\n",
      "  Downloading tokenizers-0.15.2-cp311-none-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\nuttapong.but\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anthropic) (4.7.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\nuttapong.but\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3.5.0->anthropic) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\nuttapong.but\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->anthropic) (2023.5.7)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->anthropic)\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->anthropic)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\nuttapong.but\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->anthropic) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in c:\\users\\nuttapong.but\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->anthropic) (2.10.1)\n",
      "Collecting huggingface_hub<1.0,>=0.16.4 (from tokenizers>=0.13.0->anthropic)\n",
      "  Downloading huggingface_hub-0.22.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting filelock (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic)\n",
      "  Downloading filelock-3.13.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic)\n",
      "  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\nuttapong.but\\appdata\\roaming\\python\\python311\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\nuttapong.but\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\nuttapong.but\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\nuttapong.but\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\nuttapong.but\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.42.1->huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nuttapong.but\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.2.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nuttapong.but\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (1.26.16)\n",
      "Downloading anthropic-0.21.3-py3-none-any.whl (851 kB)\n",
      "   ---------------------------------------- 0.0/851.6 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 61.4/851.6 kB 1.1 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 204.8/851.6 kB 2.5 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 337.9/851.6 kB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 471.0/851.6 kB 2.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 706.6/851.6 kB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 851.6/851.6 kB 3.6 MB/s eta 0:00:00\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "   ---------------------------------------- 0.0/75.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 75.6/75.6 kB ? eta 0:00:00\n",
      "Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "   ---------------------------------------- 0.0/77.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 77.9/77.9 kB 4.5 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.15.2-cp311-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.6/2.2 MB 17.8 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.0/2.2 MB 16.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.5/2.2 MB 13.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.0/2.2 MB 14.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 11.6 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.22.1-py3-none-any.whl (388 kB)\n",
      "   ---------------------------------------- 0.0/388.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 388.6/388.6 kB 12.2 MB/s eta 0:00:00\n",
      "Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "   ---------------------------------------- 0.0/172.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 172.0/172.0 kB ? eta 0:00:00\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "   ---------------------------------------- 0.0/58.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 58.3/58.3 kB 3.2 MB/s eta 0:00:00\n",
      "Downloading filelock-3.13.3-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: h11, fsspec, filelock, distro, huggingface_hub, httpcore, tokenizers, httpx, anthropic\n",
      "Successfully installed anthropic-0.21.3 distro-1.9.0 filelock-3.13.3 fsspec-2024.3.1 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 huggingface_hub-0.22.1 tokenizers-0.15.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script distro.exe is installed in 'c:\\Users\\nuttapong.but\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script huggingface-cli.exe is installed in 'c:\\Users\\nuttapong.but\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script httpx.exe is installed in 'c:\\Users\\nuttapong.but\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 23.3 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### สร้างฟังชั่นเพื่อใช้โมเดล"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = anthropic.Anthropic(\n",
    "    api_key=\"replace with your api key\",\n",
    ")\n",
    "\n",
    "def query_anthropic_model(prompt, model=\"claude-3-haiku-20240307\", temperature=0):\n",
    "    try:\n",
    "        # Construct the system preferences string according to your requirements\n",
    "        system_preferences = \"\"\"\n",
    "            - เพศหญิง\n",
    "            - คุณครู\n",
    "            - ใส่ใจ\n",
    "            - แทนตัวเองว่า 'พี่'\n",
    "            - แทนนักเรียนว่า 'น้อง'\n",
    "        \"\"\"\n",
    "        \n",
    "        # Create a message with the Anthropics client\n",
    "        message = client.messages.create(\n",
    "            model=model,  # Specify the model [claude-3-opus-20240229, claude-3-sonnet-20240229, claude-3-haiku-20240307]\n",
    "            max_tokens=4096,\n",
    "            temperature=temperature,\n",
    "            system=system_preferences,  # Apply the system preferences\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        # Return the 'text' content of the first ContentBlock in the response\n",
    "        return message.content[0].text if message.content else \"No response text.\"\n",
    "    except Exception as e:\n",
    "        # Return the exception message in case of an error\n",
    "        return str(e)\n",
    "\n",
    "# Example usage of the function\n",
    "#response = query_anthropic_model(\"Hi Claude.\", model=\"claude-3-haiku-20240307\", temperature=0)\n",
    "#print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loop กับขั้อมูล และ ส่งออกเป็น csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process rows as per your requirements\n",
    "for index, row in df.iterrows():\n",
    "    prompt = generate_prompt_from_row(row)\n",
    "    if prompt is None:\n",
    "        continue  # Skip processing this row\n",
    "    suggestion = query_anthropic_model(prompt, temperature=0)\n",
    "    df.at[index, 'Suggestions'] = suggestion\n",
    "\n",
    "# Save the updated DataFrame\n",
    "df.to_csv(r'C:\\Users\\nuttapong.but\\Downloads\\MedSchool_SuggestionList_Anthropic.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GEMINI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Received response code 401, Message: {\n",
      "  \"error\": {\n",
      "    \"code\": 401,\n",
      "    \"message\": \"Request had invalid authentication credentials. Expected OAuth 2 access token, login cookie or other valid authentication credential. See https://developers.google.com/identity/sign-in/web/devconsole-project.\",\n",
      "    \"status\": \"UNAUTHENTICATED\"\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Set your Gemini API key here\n",
    "API_KEY = 'replace with your api key'\n",
    "# Specify the Gemini endpoint URL, including the API key in the query parameter\n",
    "ENDPOINT_URL = 'https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent'\n",
    "\n",
    "def get_access_token(client_id, client_secret):\n",
    "    # This URL might change based on Google's documentation\n",
    "    token_url = \"https://oauth2.googleapis.com/token\"\n",
    "    payload = {\n",
    "        \"client_id\": client_id,\n",
    "        \"client_secret\": client_secret,\n",
    "        \"scope\": \"scope_of_the_gemini_api\",\n",
    "        \"grant_type\": \"client_credentials\",  # This might vary\n",
    "    }\n",
    "    response = requests.post(token_url, data=payload)\n",
    "    return response.json().get(\"access_token\")\n",
    "    \n",
    "\n",
    "# Define a function to query the Gemini model\n",
    "def query_gemini_model(prompt, temperature=0):\n",
    "    # Headers for the API request\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {API_KEY}',\n",
    "        'Content-Type': 'application/json',\n",
    "    }\n",
    "    # Define the data to be sent in the API request\n",
    "    data = {\n",
    "        'prompt': {\n",
    "            'text': prompt  # Adjust based on the Gemini API's expected prompt format\n",
    "        },\n",
    "        'temperature': temperature,\n",
    "        # Add additional parameters here as required by the Gemini API\n",
    "    }\n",
    "    try:\n",
    "        # Make the API request, appending the API key to the URL\n",
    "        response = requests.post(f'{ENDPOINT_URL}?key={API_KEY}', headers=headers, json=data)\n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            # Parse the response JSON and return the desired information\n",
    "            # Adjust this based on the actual structure of Gemini's response\n",
    "            return response.json()['responses'][0]['text']  # Example path to the generated text\n",
    "        else:\n",
    "            return f'Error: Received response code {response.status_code}, Message: {response.text}'\n",
    "    except Exception as e:\n",
    "        return f'Exception occurred: {str(e)}'\n",
    "\n",
    "# Example usage\n",
    "prompt = \"What is the meaning of life?\"\n",
    "response = query_gemini_model(prompt, temperature=0.5)\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
